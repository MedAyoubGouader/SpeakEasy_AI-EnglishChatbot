{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53bc1e7a",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£ CONFIGURATION & API KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930c8f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API Key configured!\n",
      "   GROQ_API_KEY: YOUR_GROQ_API...\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”‘ API CONFIGURATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import os\n",
    "\n",
    "# Set API Keys\n",
    "os.environ[\"GROQ_API_KEY\"] = \"YOUR_GROQ_API_KEY_HERE\"\n",
    "\n",
    "# Verify\n",
    "print(\"âœ… API Key configured!\")\n",
    "print(f\"   GROQ_API_KEY: {os.environ['GROQ_API_KEY'][:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca2caa6",
   "metadata": {},
   "source": [
    "---\n",
    "## 2ï¸âƒ£ IMPORTS & DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15bbde9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.text_splitter'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Voice\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgtts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gTTS\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.text_splitter'"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“¦ IMPORTS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Core\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "# LLM & AI\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Voice\n",
    "from gtts import gTTS\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913153fc",
   "metadata": {},
   "source": [
    "---\n",
    "## 3ï¸âƒ£ LLM MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¤– LLM MODEL - Groq Llama 3.3 70B\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Initialize Groq client\n",
    "groq_client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "# LangChain ChatGroq for advanced usage\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1500,\n",
    "    groq_api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "# Test LLM\n",
    "test_response = groq_client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say 'LLM Ready' in 2 words\"}],\n",
    "    max_tokens=10\n",
    ")\n",
    "print(f\"âœ… LLM Model initialized!\")\n",
    "print(f\"   Model: llama-3.3-70b-versatile\")\n",
    "print(f\"   Test: {test_response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450bcb3f",
   "metadata": {},
   "source": [
    "---\n",
    "## 4ï¸âƒ£ EMBEDDINGS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ§  EMBEDDINGS - HuggingFace Sentence Transformers\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Initialize embeddings model\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# Test embeddings\n",
    "test_embedding = embeddings.embed_query(\"Hello world\")\n",
    "print(f\"âœ… Embeddings model initialized!\")\n",
    "print(f\"   Model: all-MiniLM-L6-v2\")\n",
    "print(f\"   Embedding dimension: {len(test_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55087d2e",
   "metadata": {},
   "source": [
    "---\n",
    "## 5ï¸âƒ£ CHROMADB VECTOR DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9718c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ—„ï¸ CHROMADB - Vector Database for English Learning Content\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "CHROMA_DB_PATH = \"english_learning_db\"\n",
    "\n",
    "def load_or_create_vectordb():\n",
    "    \"\"\"\n",
    "    Load existing ChromaDB or create new one from data files.\n",
    "    \"\"\"\n",
    "    # Check if DB exists\n",
    "    if Path(CHROMA_DB_PATH).exists():\n",
    "        print(\"ğŸ“‚ Loading existing ChromaDB...\")\n",
    "        vectordb = Chroma(\n",
    "            persist_directory=CHROMA_DB_PATH,\n",
    "            embedding_function=embeddings\n",
    "        )\n",
    "        print(f\"âœ… ChromaDB loaded! Documents: {vectordb._collection.count()}\")\n",
    "        return vectordb\n",
    "    \n",
    "    # Create new DB from data files\n",
    "    print(\"ğŸ“š Creating new ChromaDB from data files...\")\n",
    "    \n",
    "    data_path = Path(\"data\")\n",
    "    all_texts = []\n",
    "    all_metadatas = []\n",
    "    \n",
    "    # Load all .txt files from data folder\n",
    "    if data_path.exists():\n",
    "        for txt_file in data_path.glob(\"*.txt\"):\n",
    "            try:\n",
    "                content = txt_file.read_text(encoding='utf-8')\n",
    "                category = txt_file.stem  # filename without extension\n",
    "                \n",
    "                # Split into chunks\n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=500,\n",
    "                    chunk_overlap=50\n",
    "                )\n",
    "                chunks = text_splitter.split_text(content)\n",
    "                \n",
    "                for chunk in chunks:\n",
    "                    all_texts.append(chunk)\n",
    "                    all_metadatas.append({\"category\": category, \"source\": txt_file.name})\n",
    "                \n",
    "                print(f\"   âœ“ Loaded {txt_file.name}: {len(chunks)} chunks\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âœ— Error loading {txt_file.name}: {e}\")\n",
    "    \n",
    "    if all_texts:\n",
    "        # Create ChromaDB\n",
    "        vectordb = Chroma.from_texts(\n",
    "            texts=all_texts,\n",
    "            embedding=embeddings,\n",
    "            metadatas=all_metadatas,\n",
    "            persist_directory=CHROMA_DB_PATH\n",
    "        )\n",
    "        print(f\"âœ… ChromaDB created! Total documents: {len(all_texts)}\")\n",
    "        return vectordb\n",
    "    else:\n",
    "        print(\"âš ï¸ No data files found. Creating empty DB.\")\n",
    "        vectordb = Chroma(\n",
    "            persist_directory=CHROMA_DB_PATH,\n",
    "            embedding_function=embeddings\n",
    "        )\n",
    "        return vectordb\n",
    "\n",
    "# Initialize ChromaDB\n",
    "vectordb = load_or_create_vectordb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b557c",
   "metadata": {},
   "source": [
    "---\n",
    "## 6ï¸âƒ£ RETRIEVAL FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ” RETRIEVAL - Search relevant content from ChromaDB\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def retrieve_context(query, k=3):\n",
    "    \"\"\"\n",
    "    Search ChromaDB for relevant English learning content.\n",
    "    \n",
    "    Args:\n",
    "        query: User question\n",
    "        k: Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        Concatenated relevant content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = vectordb.similarity_search(query, k=k)\n",
    "        \n",
    "        if results:\n",
    "            context = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "            return context\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Retrieval error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Test retrieval\n",
    "test_context = retrieve_context(\"present perfect tense\")\n",
    "print(\"âœ… Retrieval function ready!\")\n",
    "print(f\"   Test query: 'present perfect tense'\")\n",
    "print(f\"   Retrieved: {len(test_context)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818afb1",
   "metadata": {},
   "source": [
    "---\n",
    "## 7ï¸âƒ£ PROMPT TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d53bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“ PROMPT TEMPLATES - Category-specific prompts\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert English tutor. Your role is to help users learn English effectively.\n",
    "\n",
    "User's level: {level}\n",
    "\n",
    "When responding:\n",
    "1. Be friendly, encouraging, and patient\n",
    "2. Explain concepts clearly with examples\n",
    "3. Correct grammar mistakes gently:\n",
    "   ğŸ“ **Correction:** [what was wrong]\n",
    "   âœ… **Better:** [corrected version]\n",
    "   ğŸ’¡ **Tip:** [brief explanation]\n",
    "4. Ask follow-up questions to encourage practice\n",
    "5. Use the context provided when relevant\n",
    "\n",
    "Context from knowledge base:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "CATEGORY_PROMPTS = {\n",
    "    'grammar': \"\"\"Focus on grammar rules. Explain:\n",
    "1. The grammatical structure\n",
    "2. When to use it\n",
    "3. Common mistakes to avoid\n",
    "4. 2-3 example sentences\"\"\",\n",
    "    \n",
    "    'vocabulary': \"\"\"Focus on vocabulary. Include:\n",
    "1. Clear definition\n",
    "2. Pronunciation guide\n",
    "3. Synonyms and antonyms\n",
    "4. Example sentences in context\"\"\",\n",
    "    \n",
    "    'pronunciation': \"\"\"Focus on pronunciation. Explain:\n",
    "1. How to pronounce the sound/word\n",
    "2. IPA transcription if relevant\n",
    "3. Common pronunciation mistakes\n",
    "4. Practice tips\"\"\",\n",
    "    \n",
    "    'conversation': \"\"\"Focus on conversational English. Include:\n",
    "1. Natural expressions to use\n",
    "2. Common phrases\n",
    "3. Cultural context if relevant\n",
    "4. Practice dialogue examples\"\"\",\n",
    "    \n",
    "    'general': \"\"\"Help the user with their English question.\n",
    "Be comprehensive but concise.\"\"\"\n",
    "}\n",
    "\n",
    "print(\"âœ… Prompt templates defined!\")\n",
    "print(f\"   Categories: {list(CATEGORY_PROMPTS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e607c76",
   "metadata": {},
   "source": [
    "---\n",
    "## 8ï¸âƒ£ QUERY CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b762b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ·ï¸ QUERY CLASSIFICATION - Detect question type\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def classify_query(query):\n",
    "    \"\"\"\n",
    "    Classify the user query into a learning category.\n",
    "    \n",
    "    Returns: category string\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Grammar keywords\n",
    "    grammar_keywords = ['tense', 'verb', 'noun', 'adjective', 'adverb', 'preposition',\n",
    "                        'article', 'pronoun', 'conditional', 'passive', 'active',\n",
    "                        'present', 'past', 'future', 'perfect', 'continuous',\n",
    "                        'grammar', 'structure', 'sentence', 'clause']\n",
    "    \n",
    "    # Vocabulary keywords\n",
    "    vocab_keywords = ['word', 'meaning', 'vocabulary', 'synonym', 'antonym',\n",
    "                      'definition', 'means', 'mean', 'what is', \"what's\"]\n",
    "    \n",
    "    # Pronunciation keywords\n",
    "    pronunciation_keywords = ['pronounce', 'pronunciation', 'sound', 'accent',\n",
    "                              'speak', 'say', 'ipa', 'phonetic']\n",
    "    \n",
    "    # Conversation keywords\n",
    "    conversation_keywords = ['conversation', 'dialogue', 'talk', 'speak',\n",
    "                             'expression', 'phrase', 'idiom', 'slang']\n",
    "    \n",
    "    # Check categories\n",
    "    if any(kw in query_lower for kw in grammar_keywords):\n",
    "        return 'grammar'\n",
    "    elif any(kw in query_lower for kw in vocab_keywords):\n",
    "        return 'vocabulary'\n",
    "    elif any(kw in query_lower for kw in pronunciation_keywords):\n",
    "        return 'pronunciation'\n",
    "    elif any(kw in query_lower for kw in conversation_keywords):\n",
    "        return 'conversation'\n",
    "    else:\n",
    "        return 'general'\n",
    "\n",
    "# Test classification\n",
    "test_queries = [\n",
    "    \"What is the present perfect tense?\",\n",
    "    \"What does 'serendipity' mean?\",\n",
    "    \"How do I pronounce 'thorough'?\",\n",
    "    \"How to start a conversation?\"\n",
    "]\n",
    "\n",
    "print(\"âœ… Query classifier ready!\")\n",
    "for q in test_queries:\n",
    "    print(f\"   '{q[:30]}...' â†’ {classify_query(q)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e9ecd",
   "metadata": {},
   "source": [
    "---\n",
    "## 9ï¸âƒ£ CHAT ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2284fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¬ CHAT ENGINE - Main conversation handler\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# User settings\n",
    "user_settings = {\n",
    "    \"level\": \"Intermediate\",  # Beginner, Intermediate, Advanced\n",
    "    \"voice_enabled\": True,\n",
    "    \"correction_enabled\": True\n",
    "}\n",
    "\n",
    "def chat(user_message, use_rag=True):\n",
    "    \"\"\"\n",
    "    Main chat function. Processes user message and returns AI response.\n",
    "    \n",
    "    Args:\n",
    "        user_message: User's question or message\n",
    "        use_rag: Whether to use RAG (retrieve from ChromaDB)\n",
    "    \n",
    "    Returns:\n",
    "        AI response string\n",
    "    \"\"\"\n",
    "    global conversation_history\n",
    "    \n",
    "    # Classify query\n",
    "    category = classify_query(user_message)\n",
    "    \n",
    "    # Retrieve context if RAG enabled\n",
    "    context = \"\"\n",
    "    if use_rag:\n",
    "        context = retrieve_context(user_message, k=3)\n",
    "    \n",
    "    # Build system prompt\n",
    "    system_prompt = SYSTEM_PROMPT.format(\n",
    "        level=user_settings[\"level\"],\n",
    "        context=context if context else \"No specific context available.\"\n",
    "    )\n",
    "    \n",
    "    # Add category-specific instructions\n",
    "    category_instruction = CATEGORY_PROMPTS.get(category, CATEGORY_PROMPTS['general'])\n",
    "    system_prompt += f\"\\n\\n{category_instruction}\"\n",
    "    \n",
    "    # Add to history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    try:\n",
    "        # Call LLM\n",
    "        response = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                *conversation_history[-10:]  # Keep last 10 messages\n",
    "            ],\n",
    "            max_tokens=1000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        assistant_message = response.choices[0].message.content\n",
    "        \n",
    "        # Add to history\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "        \n",
    "        return assistant_message\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error: {type(e).__name__}: {e}\"\n",
    "        return error_msg\n",
    "\n",
    "def clear_history():\n",
    "    \"\"\"Clear conversation history\"\"\"\n",
    "    global conversation_history\n",
    "    conversation_history = []\n",
    "    print(\"âœ… Conversation history cleared!\")\n",
    "\n",
    "def set_level(level):\n",
    "    \"\"\"Set user's English level\"\"\"\n",
    "    user_settings[\"level\"] = level\n",
    "    print(f\"âœ… Level set to: {level}\")\n",
    "\n",
    "print(\"âœ… Chat engine ready!\")\n",
    "print(f\"   Level: {user_settings['level']}\")\n",
    "print(f\"   Voice: {user_settings['voice_enabled']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e0aa1",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ”Ÿ TEXT-TO-SPEECH (TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”Š TEXT-TO-SPEECH - Voice output\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def speak(text, accent=\"com\"):\n",
    "    \"\"\"\n",
    "    Convert text to speech and play it.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to speak\n",
    "        accent: 'com' (US), 'co.uk' (UK), 'com.au' (Australian)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate speech\n",
    "        tts = gTTS(text=text[:500], lang='en', tld=accent)\n",
    "        \n",
    "        # Save to temp file\n",
    "        audio_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
    "        tts.save(audio_file.name)\n",
    "        \n",
    "        # Display audio player in notebook\n",
    "        display(Audio(audio_file.name, autoplay=True))\n",
    "        \n",
    "        return audio_file.name\n",
    "    except Exception as e:\n",
    "        print(f\"TTS Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Text-to-Speech ready!\")\n",
    "print(\"   Usage: speak('Hello world')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb009d9",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£1ï¸âƒ£ CHATBOT CLASS (For Streamlit Export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¤– CHATBOT CLASS - Complete encapsulated chatbot\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class EnglishLearningChatbot:\n",
    "    \"\"\"\n",
    "    Complete English Learning Chatbot class.\n",
    "    Can be imported into Streamlit app.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key=None):\n",
    "        self.api_key = api_key or os.environ.get(\"GROQ_API_KEY\")\n",
    "        self.client = Groq(api_key=self.api_key)\n",
    "        self.history = []\n",
    "        self.level = \"Intermediate\"\n",
    "        self.vectordb = vectordb\n",
    "        \n",
    "    def chat(self, message):\n",
    "        \"\"\"Send message and get response\"\"\"\n",
    "        return chat(message)\n",
    "    \n",
    "    def speak(self, text):\n",
    "        \"\"\"Convert text to speech\"\"\"\n",
    "        return speak(text)\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Clear history\"\"\"\n",
    "        clear_history()\n",
    "    \n",
    "    def set_level(self, level):\n",
    "        \"\"\"Set English level\"\"\"\n",
    "        set_level(level)\n",
    "        self.level = level\n",
    "\n",
    "# Create global instance\n",
    "chatbot = EnglishLearningChatbot()\n",
    "\n",
    "print(\"âœ… EnglishLearningChatbot class ready!\")\n",
    "print(\"   Usage: chatbot.chat('your question')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa20ac4",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ¯ INTERACTIVE CHAT\n",
    "## Use the cells below to chat with the bot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df11526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’¬ CHAT - Change the question and run this cell!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# ğŸ‘‡ Change your question here:\n",
    "question = \"What is the conditional tense in English?\"\n",
    "\n",
    "# Get response\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ‘¤ You: {question}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = chat(question)\n",
    "\n",
    "print(f\"\\nğŸ¤– Tutor:\\n{response}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”Š LISTEN TO RESPONSE - Run to hear the last response\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if conversation_history:\n",
    "    last_response = conversation_history[-1][\"content\"]\n",
    "    print(\"ğŸ”Š Playing audio...\")\n",
    "    speak(last_response)\n",
    "else:\n",
    "    print(\"âš ï¸ No response to play. Chat first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fcf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âš™ï¸ SETTINGS - Change chatbot settings\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Set your English level:\n",
    "# Options: \"Beginner\", \"Intermediate\", \"Advanced\"\n",
    "set_level(\"Intermediate\")\n",
    "\n",
    "# Clear conversation history (uncomment to use):\n",
    "# clear_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1c0124",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“¤ EXPORT FOR STREAMLIT\n",
    "\n",
    "The `EnglishLearningChatbot` class can be imported into your Streamlit app:\n",
    "\n",
    "```python\n",
    "# In your streamlit app:\n",
    "from ENGLISH_CHATBOT_IMPLEMENTATION import chatbot\n",
    "\n",
    "response = chatbot.chat(\"What is present perfect?\")\n",
    "chatbot.speak(response)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
